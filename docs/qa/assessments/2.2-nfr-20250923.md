# NFR Assessment: Story 2.2

date: 2025-09-23
reviewer: Quinn (Test Architect)

## Scope

- Story: `2.2.queue-orchestration`
- NFR Domains Considered: reliability, performance, observability, security
- Source References:
  - `docs/architecture/10-security-and-performance.md#Queue/Compute SLO`
  - `docs/qa/assessments/2.2-test-design-20250923.md`
  - `docs/stories/2.2.queue-orchestration.md`
  - Service tests under `services/backtest/tests`

## Reliability

### Findings
- Orchestrator unit/integration tests exercise concurrency gates, retry backoff, and owner isolation (`services/backtest/tests/test_orchestrator.py`, `services/backtest/tests/test_worker.py`, `services/backtest/tests/test_main_internal_optimizations.py`).
- However, no chaos or failure-injection tests simulate Redis outage, lock contention, or multi-process concurrency (AC2 risk TECH-301 remains open).
- Top-N aggregation consistency risk (DATA-140) partially mitigated by tests but lacks persistence durability checks.

### Status: CONCERNS

### Actions
1. Add integration test simulating orchestrator restart/lock contention to ensure queued tasks resume correctly.
2. Introduce resilience scenario: mock Redis failure and verify graceful degradation or retry.
3. Validate summary/Top-N persistence by simulating storage flush and ensuring rebuild logic.

## Performance

### Findings
- Unit tests confirm backoff but no performance metrics ensure queue wait ≤ 30s P95 (Queue/Compute SLO).
- CI pipelines do not run orchestrator performance regression or load test; only web perf baseline exists.
- No profiling or rate-limit measurement for throttled tasks under sustained load.

### Status: FAIL

### Actions
1. Create load test (locust/k6) to submit > concurrency-limit jobs and verify queue wait metrics.
2. Collect queue wait histogram via observability pipeline; assert P95 in automated test (or synthetic check) meets ≤2min requirement.
3. Add perf baseline step in CI running orchestrator stress script with 100+ tasks monitoring throughput.

## Observability

### Findings
- `services/backtest/app/observability.py` provides metric/log hooks; tests confirm toggles but not integration.
- No dashboards or alert wiring documented for queue depth, throttled ratios, or retry exhaustion; risk OPS-125 still open.
- API exposes diagnostics fields but there is no automated check verifying instrumentation shipping to telemetry sink.

### Status: CONCERNS

### Actions
1. Define metric schema (queue_wait_seconds, throttled_requests, active_jobs) in observability runbook and ensure exporters configured.
2. Add integration test verifying log payload emitted when OBS_ENABLED=true (currently only unit check).
3. Ensure CI verifies observability pipeline by running smoke collector or sending sample event through.

## Security

### Findings
- Authentication/authorization enforced for status endpoints (unit/integration tests verify access control).
- Rate limiting for optimization submission is referenced but not implemented/tested; no evidence of tenant isolation for queue metrics.
- Internal orchestrator secret enforced; missing audit/logging for admin operations.

### Status: PASS (with observations)

### Actions
1. Implement rate-limit enforcement test covering repeated submissions from same owner.
2. Audit log for orchestrator admin endpoints; ensure secret rotation documented.
3. Validate multi-tenant metric segregation in observability pipeline.

## Summary

| Domain        | Status    |
| ------------- | --------- |
| Reliability   | CONCERNS  |
| Performance   | FAIL      |
| Observability | CONCERNS  |
| Security      | PASS      |

## Recommended Gate Disposition
- Due to performance SLO validation gaps and reliability/observability concerns, overall gate recommendation: **CONCERNS** until load/chaos coverage added and CI incorporates orchestrator performance instrumentation.

